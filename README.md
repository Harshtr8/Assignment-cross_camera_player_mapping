# âš½ Cross-Camera Player Re-Identification â€“ Liat.ai AI Intern Assignment

This AI project tackles the problem of tracking and re-identifying players across **multiple camera views** using deep visual features and YOLO-based object detection.

âœ… Cross-view identity mapping  
âœ… ResNet-based appearance embeddings  
âœ… End-to-end video processing pipeline  
âœ… Self-contained and easy to run  

---

## ğŸ¬ Demo Video Outputs

**[ğŸ“¹ broadcast_tracked_output.mp4](./outputs/broadcast_tracked_output.mp4)**  
**[ğŸ“¹ tacticam_reid_output.mp4](./outputs/tacticam_reid_output.mp4)**

Each shows tracked player IDs with consistency across views.

---

## ğŸš€ Features

- ğŸ¯ **YOLOv8 Object Detection**  
- ğŸ§  **Deep Feature Embeddings via ResNet-50**  
- ğŸ” **Appearance-based Tracking**  
- ğŸ”„ **Cross-Camera ID Mapping with Cosine Similarity**  
- ğŸ¥ **Final Output Videos with Re-ID**  
- ğŸ“ **Well-documented, reproducible pipeline**  

---

## ğŸ› ï¸ Tech Stack

- Ultralytics YOLOv8 for detection  
- Torch + TorchVision (ResNet50) for embeddings  
- OpenCV for video I/O  
- FAISS/Numpy for similarity matching  
- YAML & JSON for configuration and data  
- TQDM for progress visualization  

---

## ğŸ“‚ Folder Structure

```
cross_camera_player_mapping/
â”œâ”€â”€ app.py                       # Main pipeline runner
â”œâ”€â”€ draw.py                      # Visualize final re-ID outputs
â”œâ”€â”€ config.yaml                  # Input/output configuration
â”œâ”€â”€ README.md                    # This documentation file
â”œâ”€â”€ report.md                    # Summary of methodology
â”œâ”€â”€ requirements.txt             # Dependencies
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ broadcast.mp4            # Broadcast view input
â”‚   â””â”€â”€ tacticam.mp4             # Tacticam view input
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ broadcast_tracked.json
â”‚   â”œâ”€â”€ tacticam_tracked.json
â”‚   â”œâ”€â”€ tacticam_reid.json
â”‚   â”œâ”€â”€ broadcast_tracked_output.mp4
â”‚   â””â”€â”€ tacticam_reid_output.mp4
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ detect.py
â”‚   â”œâ”€â”€ reid.py
â”‚   â”œâ”€â”€ tracker.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ feature_extractor.py
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the repo

```bash
git clone https://github.com/harshtr8/cross_camera_player_mapping.git
cd cross_camera_player_mapping
```

### 2. Create a virtual environment

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Download YOLOv8 detection model (if not included)

Place the fine-tuned YOLOv8 model (`yolov8n.pt`) in the root or `models/` directory as defined in `config.yaml`.

---

## ğŸ§ª Run the Pipeline

### Detect â†’ Track â†’ Re-ID â†’ Visualize

```bash
python app.py
```

### Visualize Final Output Videos

```bash
python draw.py
```

---

## ğŸ§¾ Output Files

| File                               | Description                                      |
|------------------------------------|--------------------------------------------------|
| `broadcast_tracked.json`          | Tracked broadcast detections + ResNet features   |
| `tacticam_tracked.json`           | Tracked tacticam detections + features           |
| `tacticam_reid.json`              | tacticam detections re-ID'ed to match broadcast  |
| `broadcast_tracked_output.mp4`    | Video with tracked IDs in broadcast view         |
| `tacticam_reid_output.mp4`        | Video with consistent IDs from cross-view logic  |

---

## ğŸ“Œ Configuration File

Edit `config.yaml` to change paths or model file:

```yaml
video:
  broadcast: data/broadcast.mp4
  tacticam: data/tacticam.mp4

output_dir: outputs
model_path: yolov8n.pt
```

---

## ğŸ“„ Report Highlights (See `report.md`)

- Used **YOLOv8** for detection and ResNet50 embeddings for visual identity.
- Matched players across cameras using **cosine similarity of appearance vectors**.
- Handled invalid crops and noise via bounding box filtering and thresholding.
- Code is modular, readable, and tracks all detections end-to-end.
- Can be extended to **multi-game/multi-view pipelines** with clustering and ID propagation.

---

## ğŸ“¦ Dependencies

```txt
ultralytics==8.0.x
torch>=2.0
torchvision
opencv-python
scikit-learn
PyYAML
tqdm
numpy
```

Tested on: `Python 3.10`, `Windows 11`, `GPU optional`

---

## ğŸ“¬ Submission

ğŸ“¤ Submit this folder (GitHub repo or Google Drive link) to:

- arshdeep@liat.ai  
- rishit@liat.ai

---

## ğŸ‘¨â€ğŸ’» Author

Submitted by: **Harsh Tripathi**  
For: **Liat.ai AI Intern Role**  
Date: **14-07-2025**